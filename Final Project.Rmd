---
title: "Final Project Part 3"
author: "Justin Yu"
date: "2022-12-01"
output:
  word_document:
    toc: yes
    toc_depth: '3'
  pdf_document:
    df_print: kable
    toc: yes
    toc_depth: 3
    number_sections: yes
    latex_engine: xelatex
subtitle: The Effects of Temperature and Biological Organisms on the Dissolved Oxygen
  in the Water of Lakes
mainfont: Times New Roman
fontsize: 12pt
---

```{r, message=FALSE, echo=FALSE}

# Load Libraries:
library(tidyverse)
library(readxl)
library(grid)
library(gridExtra)
library(car)
library(gtsummary)
```

\newpage
# Introduction:

|       Contrary to popular beliefs, oxygen production comes mostly from the ocean and lakes and not trees. This production accounts for 50%-80% of Earth's oxygen and can be influenced by temperature and phytoplankton (microscopic marine algae) among other factors.$_{[4]}$ Previous studies have shown that increased levels of phytoplankton can lead to higher levels of dissolved oxygen in water.$_{[2]}$ Temperature can also affect the amount of dissolved oxygen in the water as cold water can hold more oxygen than warm water.$_{[1]}$This study supports these findings and the importance of these bio-organisms in oxygen production for addressing climate change and sustainable development. We need to ask ourselves:


$$\underline{\text{What are the effects of temperature and biological organisms like phytoplankton}}$$
$$\underline{\text{have on the dissolved oxygen in the water of lakes?}}$$
The purpose of this study is thus to explore these potential effects on dissolved oxygen and determine the strengths of the effect.


\newpage
# Method:

|       The study used data from the "Lake Simcoe Monitoring" program on the Ontario Government website, which provided measurements of various organisms and chemicals in Lake Simcoe's water and the water quality from 1980-2016. The analysis focused on the relationship between phytoplankton and temperature on dissolved oxygen levels. The relevant variables in the dataset include:

1. The dissolved oxygen levels in the lake water. ($\frac{mg}{L}$)
2. The levels of various phytoplanktons found in the water (Diatoms, Chrysophytes, Chlorophytes, Cryptophytes, Cyanobacteria, Dinoflagellates, Euglenophytes) ($\frac{mm^3}{L}$)
3. The temperature of the water. (C)

|       Our overall analysis will involve a linear regression to analyse the relationship of oxygen levels in Lake Simcoe and how it is affected by temperature and different types of phytoplankton found in the lake. 

|       In building the linear model, various statistical tools are used to create the best model to answer the research question. The process includes combining data sets from the monitoring program, creating numerical summaries of the variables, and removing variables with insufficient observations. The data is then split into equal testing and training sets. The training set is used to test the model assumptions (linearity, homoscedasticity, independence, and normality) through residual plots and a normal qq plot, and to verify that the conditional mean response is a single function of a linear combination of the predictors and that the conditional mean of each predictor is a linear function with another predictor from the residual plots. These tests help determine whether the conditions for a linear regression model are met.

|       If the assumptions are not met but the two conditions hold, we can apply a common transformation on the data and then recheck the assumptions to see if the violations are fixed. The transformations applied to the data is determined using the Box-Cox method where the common transformation was chosen based on the proximity of the box-cox estimate. Once the model satisfy the assumptions we begin the model reduction step. We use the Anova test and partial F test to determine which predictors are insignificant and can be removed from the model and generate different models. We check for multicollinearity in these models using the variance inflation function in these models and if exists we return back to the reduction step. Problematic points were then found using cooks distance, dffitts and dfbetas. Outliers and leverage points were also highlighted based on their cut-offs calculated and the size of the dataset. We also determine the validity of these problematic points and determine if the removal is justified. 

|       After developing multiple different models, we can compare each of then based on their adjusted rsquared, Akaike information criterion (AIC or AICC) and Bayesian information criterion (BIC) to test the goodness of fit for each model. The lowest AIC/AICC/BIC model is picked taking into account how low the adjusted r squared is (if too low compared to other models, choose a model with higher AIC/AICC/BIC). The model is then verifed by running the model on the test data and comparing the coefficients of both training and testing.

\newpage
# Results:

```{r, echo=FALSE}

#Load the multiple data sets into r using read_xlsx:

Simcoe_Phytoplankton <- read_xlsx("Simcoe_phytoplankton_biovolume.xlsx")
Simcoe_Oxygen <- read_xlsx("SimcoeTemperatureAndDissolvedOxygen1980-2020.xlsx")
```

```{r, warning = FALSE, echo = FALSE, message = FALSE}

#Combining the two data sets:
#Since "Temperature_C" and "Dissolved_Oxygen" are measured Monthly and
#the Phytoplankton Variables are measured Annually, we find the average Oxygen 
#and Temperature level per year.

#Renaming the Variables from "TEMPERATURE ⁰ C" and "DISSOLVED OXYGEN (mg/L)"
#to "Temperature_C" and "Dissolved_Oxygen" for easier referencing.
Simcoe_Oxygen["Temperature_C"] <- Simcoe_Oxygen[5]
Simcoe_Oxygen["Dissolved_Oxygen"] <- Simcoe_Oxygen[6]

#Select the important variables and omit any missing observations.
Simcoe_Oxygen <- Simcoe_Oxygen %>%
  dplyr::select(STN, YEAR, Temperature_C, Dissolved_Oxygen) %>%
  na.omit()

#Collect the unique Station Names
station <- c(unique(Simcoe_Phytoplankton$Station))

#Omit these years because some stations did not record in those years and
#Phytoplankton level observation stop at 2014
#We only study for the years 1985 - 2014
years_omit <- c("1980", "1981", "1982", "1983", "1984", "2001", "2015", "2016", "2017", "2018", "2019", "2020")
Year <- c()
Temperature_C <- c()
Dissolved_Oxygen <- c()
Station <- c()

#Run a For loop to Create Vectors to store data from Simcoe Oxygen 
for (i in station) {
  Oxygen <- Simcoe_Oxygen %>%
    filter(STN == i) %>%
    group_by(YEAR) %>%
    summarise( Temperature_C = mean(Temperature_C),
               Dissolved_Oxygen = mean(Dissolved_Oxygen))
  Station <- append(Station, rep(i, length(Oxygen$YEAR)))
  Year <- append(Year,Oxygen$YEAR)
  Temperature_C <- append(Temperature_C,Oxygen$Temperature_C)
  Dissolved_Oxygen <- append(Dissolved_Oxygen,Oxygen$Dissolved_Oxygen)
}

#Remove the observations associated with the years being omitted
table3 <- tibble(Station, Year, Temperature_C, Dissolved_Oxygen)
table3 <- table3 %>%
  filter(!(Year %in% years_omit))

#Remove duplicated observations found in the Simcoe_Phytoplankton data set
#duplication errors and then filter out the years not included.
Simcoe_Phytoplankton <- Simcoe_Phytoplankton[!duplicated(Simcoe_Phytoplankton),]
Simcoe_Phytoplankton <- Simcoe_Phytoplankton %>%
  filter(!(Year %in% years_omit))

#Create an ID variable for both Data Sets
table3 <- table3 %>%
  mutate(id = c(1:length(table3$Station)))

Simcoe_Phytoplankton <- Simcoe_Phytoplankton%>%
  mutate(id = c(1:length(table3$Station)))

#Combine Both Data Sets by ID and then Select Appropriate Variables
combined <- merge(table3, Simcoe_Phytoplankton, by = "id")
combined <- combined %>%
  dplyr::select(Station.x, Year.x,  Dissolved_Oxygen, Temperature_C, Diatoms, 
         Chrysophytes, Chlorophytes, Cryptophytes, Cyanobacteria, Dinoflagellates,
         Euglenophytes)
```

```{r, echo=FALSE, message = FALSE}

#Creating a table numerical summaries for the train data:
combined %>% 
  dplyr::select(Dissolved_Oxygen, Temperature_C, Diatoms, 
         Chrysophytes, Chlorophytes, Cryptophytes, Cyanobacteria, Dinoflagellates,
         Euglenophytes) %>% 
tbl_summary(
  statistic = all_continuous() ~ "{mean}, {median}, ({sd})",
  #list missing data separately
  missing = "always") %>%
  add_n() %>% # add column with total number of non-missing observations
  modify_header(label = "**Variable**") %>% # update the column header
  bold_labels()
```
Table: Showing the Mean, Median and Standard Deviation of the Generalized Important Variables Used in the Study. The table also shows the number of observations for each variable, as well as the number of missing/unknown variables.

|       Three variables have missing values, so the observations with those values must be removed when creating the model. The variable "Euglenophytes" has 198 missing values, and removing the associated observations would leave only 34 observations to build the model with. Without imputation, the alternative is to exclude "Euglenophytes" from the model. Therefore, "Euglenophytes" is excluded from the model, resulting in 222 total observations to be split between the training and testing data.

```{r, echo = FALSE, include = FALSE}
#Split the Data into Training and Testing Data Sets

set.seed(302)
#Remove "Euglenophytes"
combined <- combined[,-c(11)]
#Create an ID variable
combined['id'] = c(1:nrow(combined))

#Remove NA Values
combined <- na.omit(combined)

#Sample without replacement 111 observations randomly into training data set
train <- combined[sample(1:nrow(combined), 111, replace=F), ]
#Put the rest in the testing data set
test <- combined[which(!(combined$id %in% train$id)),]

#Remove the Id Variable
train <- train[,-c(11)]
test <- test[,-c(11)]
```

\newpage

```{r, echo = FALSE, fig.dim = c(10,7), fig.cap = "Plot Matrix of Scatterplots Showing the Relationship between Each Variables Being used in the Study. The response variable is Dissolved Oxygen and the remaining seven variables would be the predictor variables in the linear regression model."}

#Create a Matrix Scatterplots of the Variables being Used
pairs(train[3:10], main = "Scatterplot Matrix Between Each Variable in Study")
```

|       The scatterplot matrix is used to informally check for potential violations of the model assumptions. The response appears to be normally distributed, but the predictors are skewed and may affect the linearity assumption or model fit. Homoscedasticity also appears to be violated, as the response's variability increases across values of each predictor. Formal testing is required, but a common transformation using Box Cox estimation may be applied to the variables to address these model violations.

|       Appendix A tests the assumptions formally. We can see that the residual graphs are interpretable since the two conditions (noted in the method) are not violated. We can see a violation in the Homoscedasticity assumption but the other assumptions seem to hold (linearity - no observable curves, uncorrelated errors - no separate clusters, normality - straight QQ plot). We can now apply a common transformation to the variables suggested by the Box Cox method.

\newpage
```{r, echo = FALSE, include = FALSE}

#Use to Calculate the Box-Cox Estimates for the Predictor Variables
#to Approximate to Common Transformation 
summary(powerTransform(cbind(train[,4:10])))
```

```{r, echo = FALSE, include = FALSE}
train <- na.omit(train)
train1 <- train

#Use the Common Transformations suggested by the Box-Cox Method
train$Dissolved_Oxygen <- train$Dissolved_Oxygen # Leave as is
train$Temperature_C_Sq <- (train$Temperature_C)^2 # Square Temperature
train$log_Diatoms <- log(train$Diatoms) # Log Diatoms
train$log_Chrysophytes <- log(train$Chrysophytes) # Log Chrysophytes
train$log_Chlorophytes <- log(train$Chlorophytes) # Log Chlorophytes
train$log_Cryptophytes <- log(train$Cryptophytes) # Log Cryptophytes
train$log_Cyanobacteria <- log(train$Cyanobacteria) # Log Cyanobacteria
train$Root_Dinoflagellates <- sqrt(train$Dinoflagellates) # Square root Dinoflagellates

#Create a linear model with the newly transformed variables
mod2 <- lm(train$Dissolved_Oxygen ~ ., data= train[,11:17])
summary(mod2)

#Obtain the Fitted and Residuals from the model
fit <- mod2$fitted.values
r <- mod2$residuals
plots <- list()

#Function which creates Residual Plots given Data, Residuals and Predictor Values
plot_data_column = function (data, predictor, r) {
  temp <- data.frame(data[predictor], residual = r)
  ggplot(temp, aes(x = temp[,1], y = residual)) +
      geom_point(size = 0.5) +
      labs(x = predictor, y = "Residuals")
}

#Apply the function to the Predictors in the Linear Model
myplots2 <- lapply(colnames(train[,-c(1:10)]), plot_data_column, data = train, 
                   r= r)

residual <- tibble(r, fit)

#Create a Residual vs Fitted plot
res1 <- residual %>%
  ggplot(aes(x = fit, y = r))+
  geom_point(size = 0.5)+
  labs(x = "Fitted Values", y = "Residuals")

#Create a QQ plot of the Residuals
res2 <- residual %>%
  ggplot(aes(sample = r))+
  geom_qq(size = 0.5)+
  geom_qq_line()+
  labs(x = "Normal Quantiles", y = "Residuals Quantiles")

#combine all the plots into a list
fig2 <- c(myplots2, list(res1), list(res2))
```

```{r, echo = FALSE, fig.cap= "The test of assumptions after the variables were transformed using common transformations determined by the Box-Cox Method. This figure shows the differences seen after applying the transformations as opposed to Appendix A", fig.dim=c(6,4)}

#Arrange all the plots in the list using package Grid.
grid.arrange(grobs = fig2, 
             top=textGrob("Formal Test of Assumptions For Transformed Variables \n Via Residuals and QQ Plots"))
```

|       The variables appear to satisfy the assumptions needed to model and interpret a linear model mentioned in the method. Thus we can start to build the linear model and proceed with the reduction process via Anova and Partial F Test to test and compare different models.

\newpage
```{r, include = FALSE}

#Original Model
mod1 <- lm(train1$Dissolved_Oxygen ~ ., data= train1[,-c(1,2,3)])
summary(mod1)

#Transformed Model
mod2 <- lm(train$Dissolved_Oxygen ~ ., data= train[,11:17])
#Observe the Significance of each Predictor in transformed Model 2
#We see 4 insignificant predictors log_Diatoms, log_Chrysophytes, 
#log_Cryptophytes and Root_Dinoflagellates

# first we can try removing Root_Dinoflagellates in Model 2
mod3 <- lm(train$Dissolved_Oxygen ~ ., data= train[,11:16])
# Partial F Test
anova(mod3, mod2) #F test gives permission to remove predictor from model

# second we can try removing log_Chrysophytes in Model 2
mod4 <- lm(train$Dissolved_Oxygen ~ ., data= train[,-c(1,2,3,4,5,6,7,8,9,10,13)])
#Partial F Test
anova(mod4, mod2)#F test gives permission to remove predictors from model

#we can try removing log_Diatoms in Model 4
mod5 <- lm(train$Dissolved_Oxygen ~ ., data= train[,-c(1,2,3,4,5,6,7,8,9,10,12,13)])
summary(mod5)
anova(mod5, mod2)#F test gives permission to remove predictors from model

#we can try removing log_Cryptophytes from model 5
mod6 <- lm(train$Dissolved_Oxygen ~ ., data= train[,-c(1,2,3,4,5,6,7,8,9,10,12,13,15)])
summary(mod6)
anova(mod6, mod2)#F test gives permission to remove predictors from model

#no more insignificant predictors

#We can then try to only remove log_Diatoms first from model 2
mod7 <- lm(train$Dissolved_Oxygen ~ ., data= train[,-c(1,2,3,4,5,6,7,8,9,10,12)])
#Partial F Test
anova(mod7, mod2)#F test gives permission to remove predictors from model

#We can then try to only remove log_Cryptophytes first from model 2
mod8 <- lm(train$Dissolved_Oxygen ~ ., data= train[,-c(1,2,3,4,5,6,7,8,9,10,15)])
#Partial F Test
anova(mod8, mod2)#F test gives permission to remove predictors from model
```

```{r, include = FALSE}

#Create a Function which Collects the Values Given a Model 
#and Number of Observations and returns a vector
selection = function(model, n)
{
  Rsq_adj <- summary(model)$adj.r.squared
  p <- length(model$coefficients) - 1
  AIC <- AIC(model)
  AICc <- AIC + (2*(p+2)*(p+3)/(n-p-1))
  BIC <- BIC(model)
  Lowest_VIF <- min(vif(model))
  Highest_VIF <-max(vif(model))
  res <- round(c(Rsq_adj, AIC, AICc, BIC, Lowest_VIF, Highest_VIF),3)
  names(res) <- c("Rsq_adj", "AIC", "AIC_c", "BIC", "Lowest_VIF", "Highest_VIF")
  return(res)
}

#Run the Function of all the Models
s1 <- selection(mod1, nrow(train))
s2 <- selection(mod2, nrow(train))
s3 <- selection(mod3, nrow(train))
s4 <- selection(mod4, nrow(train))
s5 <- selection(mod5, nrow(train))
s6 <- selection(mod6, nrow(train))
s7 <- selection(mod7, nrow(train))
s8 <- selection(mod8, nrow(train))
```

Table 2: Showing Different Linear Regressions Ran, the Lowest and Highest Estimates for the Variance Inflation Function are also included in the table. The full model is the original model with untransformed variables which violate the assumptions. All the models has "Dissolved_Oxygen" as the response variable. Model 2 uses all the variables which have been transformed, Model 3 is a reduced version of Model 2 (without "Root_Dinoflagellates"). Model 4 is a reduced version of Model 2 (without "log_Chrysophytes') and Model 5 and 6 further removes "log_Diatoms" and then "log_Cryptophytes" from Model 4. Model 7 is where only "log_Diatoms" is removed and model 8 is where only "log_Cryptophytes" is removed from model 2.

Model | Adjusted $R^2$ | AIC     | AICC    | BIC     |Lowest VIF  |Highest_VIF
------|----------------|---------|---------|---------|------------|-----------
 Full |    `r s1[1]`   |`r s1[2]`|`r s1[3]`|`r s1[4]`|  `r s1[5]` |   `r s1[6]`
  2   |    `r s2[1]`   |`r s2[2]`|`r s2[3]`|`r s2[4]`|  `r s2[5]` |   `r s2[6]`
------|----------------|---------|---------|---------|------------|-----------
  3   |    `r s3[1]`   |`r s3[2]`|`r s3[3]`|`r s3[4]`|  `r s3[5]` |   `r s3[6]`
------|----------------|---------|---------|---------|------------|-----------
  4   |    `r s4[1]`   |`r s4[2]`|`r s4[3]`|`r s4[4]`|  `r s4[5]` |   `r s4[6]`
  5   |    `r s5[1]`   |`r s5[2]`|`r s5[3]`|`r s5[4]`|  `r s5[5]` |   `r s5[6]`
  6   |    `r s6[1]`   |`r s6[2]`|`r s6[3]`|`r s6[4]`|  `r s6[5]` |   `r s6[6]`
------|----------------|---------|---------|---------|------------|-----------
  7   |    `r s7[1]`   |`r s7[2]`|`r s7[3]`|`r s7[4]`|  `r s7[5]` |   `r s7[6]`
------|----------------|---------|---------|---------|------------|-----------
  8   |    `r s8[1]`   |`r s8[2]`|`r s8[3]`|`r s8[4]`|  `r s8[5]` |   `r s8[6]`

|       From Table 2, we can judge which model is a better fit on the variables, than the other by comparing AICC, AIC, $R^2$ and BIC. All the models built do not show a multi-collinearity issue based on the range of their Variance Inflation Function estimates (< 5). The models have a relatively similar AIC, AICC and BIC despite having different amounts of predictors. Model 4, which is the model that does not include log_Chrysophytes, has a lower AIC, AICC and BIC relative to a higher adjusted $R^2$ compared to the other models. Based on these notations (lower AIC, etc being better) and that the model satisfies the assumptions needed for a linear model, we choose model 4 as the final model.

```{r, include = FALSE}
#Run Tests for Problematic Points
# values to use in cutoffs
n <- nrow(train)
p <- length(coef(mod4))-1

# define the cutoffs we will use
Hcut <- 2*((p+1)/n)
DFFITScut <- 2*sqrt((p+1)/n)
DFBETAcut <- 2/sqrt(n)
Dcut <- qf(0.5, p+1, n-p-1)

# identify the leverage points
h <- hatvalues(mod4)
which(h > Hcut)

# identify the outliers
r <- rstandard(mod4)
which(r < -2 | r > 2)
which(r < -4 | r > 4)

# identify influential points by Cook's distance
D <- cooks.distance(mod4)
which(D > Dcut)

# identify influential points by DFFITS
fits <- dffits(mod4)
which(abs(fits) > DFFITScut)

# identify influential points by DFBETAS
betas <- dfbetas(mod4)
dim(betas)

for(i in 1:7){
  print(paste0("Beta ", i-1))
  print(which(abs(betas[,i]) > DFBETAcut))
}

```

|       Using model 4 as the chosen model, We identified 8 leverage points in the data that are distant from the rest of the observations in the predictor space. We also identified 4 outlier observations when considering the dataset as "small", but none when considering it as "large". No observations were identified as being influential on the entire regression surface, but we identified 5 observations who influenced their own fitted values and between 5-11 observations being influential on at least one estimated coefficient. Observing the values of these problematic points (to check if any measurement errors occurred) however, it was determined that the points reasonable in context and should not be removed from the model data. Now that the training model has been developed, we compare it to the testing model.

\newpage

```{r, echo=FALSE, include=FALSE}

mod4train <- lm(train$Dissolved_Oxygen ~ ., 
                data= train[,-c(1,2,3,4,5,6,7,8,9,10,13)])

#Collect all the Estimates for the Training Model (Largest VIf, Coefficients, etc)
p1 <- length(coef(mod4train))-1
n1 <- nrow(train)
vif1 <- max(vif(mod4train))
D1 <- length(which(cooks.distance(mod4train) > qf(0.5, p1+1, n1-p1-1)))
fits1 <- length(which(abs(dffits(mod4train)) > 2*sqrt((p1+1)/n1)))
lev1 <- length(which(hatvalues(mod4train) > 2*((p1+1)/n1)))
small1 <- length(which(rstandard(mod4train) < -2 | rstandard(mod4train) > 2))
large1 <- length(which(rstandard(mod4train) < -4 | rstandard(mod4train) > 4))
R_2 <- round(summary(mod4train)$adj.r.squared, 3)

coefs1 <- round(summary(mod4train)$coefficients[,1], 3)
ses1 <- round(summary(mod4train)$coefficients[,2], 3)

#fit in test dataset
#Transform the Testing Data set
test$Dissolved_Oxygen <- test$Dissolved_Oxygen
test$Temperature_C_Sq <- (test$Temperature_C)^2
test$log_Diatoms <- log(test$Diatoms)
test$log_Chrysophytes <- log(test$Chrysophytes)
test$log_Chlorophytes <- log(test$Chlorophytes)
test$log_Cryptophytes <- log(test$Cryptophytes)
test$log_Cyanobacteria <- log(test$Cyanobacteria)
test$Root_Dinoflagellates <- sqrt(test$Dinoflagellates)

#Run the same Linear model on the Test Data
mod4test <- lm(test$Dissolved_Oxygen ~ ., 
               data= test[,-c(1,2,3,4,5,6,7,8,9,10,13)])

#Collect all the Estimates for the Testing Model (Largest VIf, Coefficients, etc)
tp1 <- length(coef(mod4test))-1
tn1 <- nrow(test)
tvif1 <- max(vif(mod4test))
tD1 <- length(which(cooks.distance(mod4test) > qf(0.5, tp1+1, tn1-tp1-1)))
tfits1 <- length(which(abs(dffits(mod4test)) > 2*sqrt((tp1+1)/tn1)))
tlev1 <- length(which(hatvalues(mod4test) > 2*((tp1+1)/tn1)))
tsmall1 <- length(which(rstandard(mod4test) < -2 | rstandard(mod4test) > 2))
tlarge1 <- length(which(rstandard(mod4test) < -4 | rstandard(mod4test) > 4))
tR_2 <- round(summary(mod4test)$adj.r.squared, 3)

tcoefs1 <- round(summary(mod4test)$coefficients[,1], 3)
tses1 <- round(summary(mod4test)$coefficients[,2], 3)

```

|Characteristic       | Model 4 (Train)| Model 4 (Test)|
|---------------------|---------------|--------------|
|Largest VIF value    | `r vif1`                              | `r tvif1`                              |
|Cook's D             | `r D1`                                | `r tD1`                                |
|DFFITS               | `r fits1`                             | `r tfits1`                             |
|Leverage Points      | `r lev1`                              | `r tlev1`                              |
|Outliers (Small)     | `r small1`                            | `r tsmall1`                            |
|Outliers (Large)     | `r large1`                            | `r tlarge1`                            |
|Violations           | none                                  | none                                   |
|---------------------|---------------------|---------------------|
|Intercept            | `r coefs1[1]` $\pm$ `r ses1[1]`       | `r tcoefs1[1]` $\pm$ `r tses1[1]`      |
|Temperature_C_Sq     | `r coefs1[2]` $\pm$ `r ses1[2]`       | `r tcoefs1[2]` $\pm$ `r tses1[2]`      |
|log_Diatoms          | `r coefs1[3]` $\pm$ `r ses1[3]`       | `r tcoefs1[3]` $\pm$ `r tses1[3]`      |
|log_Chlorophytes     | `r coefs1[4]` $\pm$ `r ses1[4]`       | `r tcoefs1[4]` $\pm$ `r tses1[4]`      |
|log_Cryptophytes     | `r coefs1[5]` $\pm$ `r ses1[5]`       | `r tcoefs1[5]` $\pm$ `r tses1[5]`      |
|log_Cyanobacteria    | `r coefs1[6]` $\pm$ `r ses1[6]`       | `r tcoefs1[6]` $\pm$ `r tses1[6]`      |
|Root_Dinoflagellates | `r coefs1[7]` $\pm$ `r ses1[7]`       | `r tcoefs1[7]` $\pm$ `r tses1[7]`      |
|Adjusted $R^2$       | `r R_2`                               | `r tR_2`                               |

Table: Summary of characteristics of Model 4 between the training and test datasets. Model 4 uses Temperature_C_Sq, log_Diatoms, log_Chlorophytes, log_Cryptophytes, log_Cyanobacteria and Root_Dinoflagellates as predictors. The Response is Dissolved_Oxygen in both models. Coefficients are presented as estimate $\pm$ SE.

|       Based on Appendix B and C, both the training and testing models seem to satisfy the conditions and assumptions of a linear regression model and both had similar residual and QQ plots. In comparing model 4 between the training data and testing data, we see some similarities in both the amount of problematic points and the VIF values. The testing data set had more outliers and points who influenced their fitted values but a lower max VIF value. The signs of coefficients remained the same for both sets, however, there is a noticeable difference in size of the coefficient in "log_Chlorophytes" and also Adjusted $R^2$. The difference seen from the Adjusted $R^2$ may suggest that the training model was over-fitted.

\newpage
# Discussion:

|       The final model displayed, helps us analyse the various effects of temperature and different types of phytoplankton on the dissolved oxygen levels found in Lake Water, thus answering our research question. By looking at the coefficients of the model, we are able to interpret what effect an increase of that variable can have on the level of dissolved oxygen in the water. For example, looking at the predictor variable of Temperature_C_Sq, we can see that it has a small and positive impact on the levels of dissolved oxygen in the lake water (with a small standard error of 0.01). Comparing this to log_Cyanobacteria, we see an increase in log_Cyanobacteria causes the dissolved oxygen levels to fall by -0.269 (with a small standard error of 0.084), it is important to not interpret this as an increase of Cyanobacteria leads to decreases in the oxygen level in water.

|       The model has some limitations, including a low adjusted r-squared of 0.299, indicating that the variability of dissolved oxygen levels is weakly explained by the predictor variables. This may be due to insufficient observations/predictors or a smaller correlation between phytoplankton and temperature and dissolved oxygen levels than initially thought. Additionally, data collected from the natural environment may be affected by other unobservable factors, such as water flow rate, that have a greater impact on dissolved oxygen levels.

|       The chosen model may be overfitted due to the difference in adjusted r-squared values between the training and testing data sets. This may be due to a small data size with insufficient samples to accurately represent all levels of input, or to the transformations applied. An overfitted model would produce biased estimates of the coefficients of the predictor variables and not accurately measure the effect on dissolved oxygen levels. To address these limitations, a larger study with more observations and possibly additional predictors would be necessary.

\newpage

# Bibliography:

**Scientific Articles Used:**

1. Khan, U. T., & Valeo, C. (2015). A new fuzzy linear regression approach for dissolved oxygen prediction. Hydrological Sciences Journal, 60(6), 1096–1119. [https://doi.org/10.1080/02626667.2014.900558](https://doi.org/10.1080/02626667.2014.900558)

2. Smith, D. W., & Piedrahita, R. H. (1988). The relation between phytoplankton and dissolved oxygen in fish ponds. Aquaculture, 68(3), 249–265. [https://doi.org/10.1016/0044-8486(88)90357-2](https://doi.org/10.1016/0044-8486(88)90357-2)

3. Wang, J., & Zhang, Z. (2020). Phytoplankton, dissolved oxygen and nutrient patterns along a eutrophic river-estuary continuum: Observation and modeling. Journal of Environmental Management, 261, 110233. [https://doi.org/10.1016/j.jenvman.2020.110233](https://doi.org/10.1016/j.jenvman.2020.110233)

**Websites used:**

4. How much oxygen comes from the ocean? NOAA's National Ocean Service. (n.d.). Retrieved October 15, 2022, from [https://oceanservice.noaa.gov/facts/ocean-oxygen.html#:~:text=Scientists%20estimate%20that%2050%2D80,smallest%20photosynthetic%20organism%20on%20Earth](https://oceanservice.noaa.gov/facts/ocean-oxygen.html#:~:text=Scientists%20estimate%20that%2050%2D80,smallest%20photosynthetic%20organism%20on%20Earth)

5. Government of Ontario. (n.d.). Lake Simcoe Monitoring - Ontario Data Catalogue. Lake Simcoe Monitoring - Datasets - Ontario Data Catalogue. Retrieved October 22, 2022, from [https://data.ontario.ca/en/dataset/lake-simcoe-monitoring](https://data.ontario.ca/en/dataset/lake-simcoe-monitoring)

6. United Nations. (n.d.). Global Population Growth and sustainable development | population division. United Nations. Retrieved October 15, 2022, from [https://www.un.org/development/desa/pd/content/global-population-growth](https://www.un.org/development/desa/pd/content/global-population-growth)

**Packages Used**

7. tidyverse [https://www.tidyverse.org/packages/](https://www.tidyverse.org/packages/)

8. grid [https://CRAN.R-project.org/package=grid](https://CRAN.R-project.org/package=grid )

9. gridExtra [https://cran.r-project.org/web/packages/gridExtra/index.html](https://cran.r-project.org/web/packages/gridExtra/index.html)

10. knitr::kable [https://rmarkdown.rstudio.com/lesson-7.html](https://rmarkdown.rstudio.com/lesson-7.html)

11. gtsummary [https://cran.r-project.org/web/packages/gtsummary/index.html](https://cran.r-project.org/web/packages/gtsummary/index.html)

\newpage

# Appendix:

## A

```{r, echo = FALSE}

#Obtain the Fitted and Residuals from the model
fit <- mod1$fitted.values
r <- mod1$residuals
plots <- list()

#Function which creates Residual Plots given Data, Residuals and Predictor Values
plot_data_column = function (data, predictor, r) {
  temp <- data.frame(data[predictor], residual = r)
  ggplot(temp, aes(x = temp[,1], y = residual)) +
      geom_point(size = 0.5) +
      labs(x = predictor, y = "Residuals")
}

#Apply the function to the Predictors in the Linear Model
myplots3 <- lapply(colnames(train1[,-c(1,2,3)]), plot_data_column, data = train1, r= r)

residual <- tibble(r, fit)

#Create a Residual vs Fitted plot
res1 <- residual %>%
  ggplot(aes(x = fit, y = r))+
  geom_point(size = 0.5)+
  labs(x = "Fitted Values", y = "Residuals")

#Create a QQ plot of the Residuals
res2 <- residual %>%
  ggplot(aes(sample = r))+
  geom_qq(size = 0.5)+
  geom_qq_line()+
  labs(x = "Normal Quantiles", y = "Residuals Quantiles")

#Create a Response vs Fitted Graph
res3 <- residual %>%
  ggplot(aes(x = fit, y = train$Dissolved_Oxygen))+
  geom_point(size = 0.5)+
  geom_abline(intercept = 0, slope = 1)+
  labs(x = "Fitted Values", y = "Dissolved_Oxygen")

#combine all the plots into a list
fig1 <- c(myplots3, list(res1), list(res2), list(res3))
```

```{r, echo = FALSE, fig.dim = c(6,5), fig.cap = "Formal Test Assumptions for the Untransformed Training Data Set. The QQ Plot represents the normality assumption and the Residual Vs Predictor Graphs can show violations of the Constant Variance Assumption. The Response vs Fitted plot is used to verify a condition of using the residual plots to interpret the assumption validity"}
#Arrange all the plots in the list into one Plot.
grid.arrange(grobs = fig1, 
             top=textGrob("Formal Test of Assumptions Via Residuals and QQ Plots"))

```

\newpage

## B
```{r, echo = FALSE, include = FALSE}
#Train Case
#Obtain the Fitted and Residuals from the model
fit <- mod4train$fitted.values
r <- mod4train$residuals
plots <- list()

#Function which creates Residual Plots given Data, Residuals and Predictor Values
plot_data_column = function (data, predictor, r) {
  temp <- data.frame(data[predictor], residual = r)
  ggplot(temp, aes(x = temp[,1], y = residual)) +
      geom_point(size = 0.5) +
      labs(x = predictor, y = "Residuals")
}

#Apply the function to the Predictors in the Linear Model
myplots3 <- lapply(colnames(train[,-c(1,2,3,4,5,6,7,8,9,10,13)]), 
                   plot_data_column, data = train, r= r)

residual <- tibble(r, fit)

#Create a Residual vs Fitted plot
res1 <- residual %>%
  ggplot(aes(x = fit, y = r))+
  geom_point(size = 0.5)+
  labs(x = "Fitted Values", y = "Residuals")

#Create a QQ plot of the Residuals
res2 <- residual %>%
  ggplot(aes(sample = r))+
  geom_qq(size = 0.5)+
  geom_qq_line()+
  labs(x = "Normal Quantiles", y = "Residuals Quantiles")

#Create a Response vs Fitted Graph
res3 <- residual %>%
  ggplot(aes(x = fit, y = train$Dissolved_Oxygen))+
  geom_point(size = 0.5)+
  geom_abline(intercept = 0, slope = 1)+
  labs(x = "Fitted Values", y = "Dissolved_Oxygen")

#combine all the plots into a list
fig3 <- c(myplots3, list(res1), list(res2), list(res3))
```

```{r, echo = FALSE, fig.dim = c(6,4), fig.cap = "Formal Test Assumptions for the Chosen Model on the Training Data Set. The QQ Plot represents the normality assumption and the Residual Vs Predictor Graphs can show violations of the Constant Variance Assumption. The Response vs Fitted plot is used to verify a condition of using the residual plots to interpret the assumption validity"}
grid.arrange(grobs = fig3, 
             top=textGrob("Formal Test of Assumptions Via Residuals and QQ Plots"))

```

\newpage


## C
```{r, r, echo = FALSE, include = FALSE}
#Test Case
#Obtain the Fitted and Residuals from the model
fit <- mod4test$fitted.values
r <- mod4test$residuals
plots <- list()

#Apply the function to the Predictors in the Linear Model
myplots4 <- lapply(colnames(test[,-c(1,2,3,4,5,6,7,8,9,10,13)]), 
                   plot_data_column, data = test, r= r)

residual <- tibble(r, fit)

#Create a Residual vs Fitted plot
res1 <- residual %>%
  ggplot(aes(x = fit, y = r))+
  geom_point(size = 0.5)+
  labs(x = "Fitted Values", y = "Residuals")

#Create a QQ plot of the Residuals
res2 <- residual %>%
  ggplot(aes(sample = r))+
  geom_qq(size = 0.5)+
  geom_qq_line()+
  labs(x = "Normal Quantiles", y = "Residuals Quantiles")

#Create a Response vs Fitted Graph
res3 <- residual %>%
  ggplot(aes(x = fit, y = test$Dissolved_Oxygen))+
  geom_point(size = 0.5)+
  geom_abline(intercept = 0, slope = 1)+
  labs(x = "Fitted Values", y = "Dissolved_Oxygen")

#combine all the plots into a list
fig4 <- c(myplots4, list(res1), list(res2), list(res3))
```


```{r, echo = FALSE, fig.dim = c(6,4), fig.cap = "Formal Test Assumptions for the Chosen Model on the Testing Data Set. The QQ Plot represents the normality assumption and the Residual Vs Predictor Graphs can show violations of the Constant Variance Assumption. The Response vs Fitted plot is used to verify a condition of using the residual plots to interpret the assumption validity"}
grid.arrange(grobs = fig4, 
             top=textGrob("Formal Test of Assumptions Via Residuals and QQ Plots"))
```
